{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install semanticscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"machine learning\"\n",
    "    # , \"artificial intelligence\", \"computer vision\",\n",
    "    # \"quantum mechanics\", \"cancer treatment\", \"COVID-19\", \n",
    "    # \"ancient civilizations\", \"economics\", \"psychology\", \"marketing\",\n",
    "    # \"music\", \"film\", \"literature\", \"education\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = SemanticScholar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for: machine learning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sch = SemanticScholar()\n",
    "all_papers = []\n",
    "\n",
    "# Fetch papers for each topic and add to the list\n",
    "for topic in topics:\n",
    "    try:\n",
    "        print(f\"Fetching papers for: {topic}\")\n",
    "        response = sch.search_paper(query=topic, bulk=True)\n",
    "        \n",
    "        # Extract raw data from the response\n",
    "        raw_data = response.raw_data\n",
    "        \n",
    "        # Append the papers to the all_papers list\n",
    "        all_papers.extend(raw_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching papers for {topic}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"semantic_scholar_combined_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_papers, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"semantic_scholar_combined_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_papers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'papers_og.csv' has been created successfully.\n",
      "Author data has been saved to 'authors.csv'.\n",
      "Paper-Author relationship data has been saved to 'author_paper_relationship.csv'.\n",
      "Field data has been saved to 'fields_of_study.csv'.\n",
      "Paper-Field relationship data has been saved to 'paper_field_relationship.csv'.\n",
      "CSV files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "csv_filename = \"papers_og.csv\"\n",
    "\n",
    "papers_data = []\n",
    "author_paper_relationship = []  # List to store paper-author relationship\n",
    "paper_field_relationship = []  # List to store paper-field relationship\n",
    "\n",
    "filtered_responses = []\n",
    "author_data = []  # List to store author names and IDs\n",
    "field_data = {}  # Dictionary to store unique fields and their IDs\n",
    "field_id_counter = 1  # Counter for assigning unique field IDs\n",
    "\n",
    "\n",
    "Journals_data = []\n",
    "Conferences_data = []\n",
    "Conf_editions = []\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header row with exact headers you provided\n",
    "    writer.writerow([\n",
    "        \"Paper_ID\", \"DOI\", \"Title\", \"Abstract\", \"Venue\", \"publicationType\", \n",
    "        \"publication_type_2\", \"venue_id\", \"journal_name\", \"pages\", \"volume\", \"Edition_id\", \"Year\", \n",
    "        \"publicationDate\", \"Citations\", \"References\", \"Authors\", \"Author_Ids\", \n",
    "        \"URL\", \"s2FieldsOfStudys\", \"Corresponding_Author_ID\"\n",
    "    ])\n",
    "\n",
    "    # Write data rows\n",
    "    for paper in response:\n",
    "        paper_id = paper.get(\"paperId\", \"Unknown\") \n",
    "        doi = paper[\"externalIds\"].get(\"DOI\", \"Unknown\")  # Get DOI if available\n",
    "        title = paper.get(\"title\", \"Unknown\")\n",
    "        abstract = paper.get(\"abstract\", \"\")\n",
    "        venue = paper.get(\"venue\", \"Unknown\")\n",
    "        publication_type = (paper.get(\"publicationVenue\") or {}).get(\"type\", \"Unknown\")\n",
    "        venue_id = (paper.get(\"publicationVenue\") or {}).get(\"id\", \"Unknown\")\n",
    "        publication_type_2 = paper.get(\"publicationTypes\", [])\n",
    "        journal_name = (paper.get(\"journal\") or {}).get(\"name\", \"Unknown\") \n",
    "        pages = (paper.get(\"journal\") or {}).get(\"pages\", \"Unknown\") \n",
    "        volume = (paper.get(\"journal\") or {}).get(\"volume\", \"Unknown\") \n",
    "\n",
    "        year = paper.get(\"year\", \"2025\")\n",
    "        publicationDate = paper.get(\"publicationDate\", \"Unknown\")\n",
    "        citation_count = paper.get(\"citationCount\", \"Unknown\")\n",
    "        reference_count = paper.get(\"referenceCount\", \"Unknown\")\n",
    "        s2FieldsOfStudys = ', '.join(sorted({s2FieldsOfStudy.get('category', \"Unknown\") for s2FieldsOfStudy in paper.get(\"s2FieldsOfStudy\", [])}))\n",
    "\n",
    "        url = paper.get(\"url\", \"Unknown\")\n",
    "\n",
    "        # Extract authors and author IDs\n",
    "        authors = [author.get('name', 'Unknown') for author in paper.get(\"authors\", [])]\n",
    "        author_ids = [author.get('authorId', 'Unknown') for author in paper.get(\"authors\", [])]\n",
    "        if any(value == \"Unknown\" or value == \"\" for value in [doi, title, venue_id, publication_type, journal_name, year, authors, author_ids]):\n",
    "            continue\n",
    "\n",
    "        if len(authors) != len(author_ids):\n",
    "            continue\n",
    "\n",
    "\n",
    "        authors_str = \", \".join(f\"{author.get('name', 'Unknown')}\" for author in paper.get(\"authors\", []))\n",
    "        author_ids_str = \", \".join(f\"{author.get('authorId', 'Unknown')}\" for author in paper.get(\"authors\", []))\n",
    "\n",
    "        # Store authors and their IDs in the list for later use\n",
    "        for author_name, author_id in zip(authors, author_ids):\n",
    "            author_data.append({\"Author_Name\": author_name, \"Author_ID\": author_id})\n",
    "\n",
    "        # Mark the first author as the corresponding author\n",
    "        corresponding_author_id = author_ids[0] if author_ids else \"Unknown\"\n",
    "        \n",
    "        # Create the paper-author relationship for each author\n",
    "        for author_id in author_ids:\n",
    "            is_corresponding = (author_id == corresponding_author_id)\n",
    "            author_paper_relationship.append({\"DOI\": doi, \"Author_ID\": author_id, \"Corresponding\": is_corresponding})\n",
    "    \n",
    "\n",
    "        # Handle fields of study\n",
    "        fields_of_study = {s2FieldsOfStudy.get('category', \"Unknown\") for s2FieldsOfStudy in paper.get(\"s2FieldsOfStudy\", [])}\n",
    "\n",
    "        # Assign unique IDs to fields of study\n",
    "        for field in fields_of_study:\n",
    "            if field not in field_data:\n",
    "                field_data[field] = field_id_counter\n",
    "                field_id_counter += 1\n",
    "\n",
    "        # Create paper-field relationship\n",
    "        for field in fields_of_study:\n",
    "            paper_field_relationship.append({\"DOI\": doi, \"Field_ID\": field_data[field]})\n",
    "\n",
    "\n",
    "        if publication_type == \"conference\":\n",
    "            Conferences_data.append({\"ID\": venue_id, \"Name\": venue, \"url\": url})\n",
    "            Conf_editions.append({\n",
    "                    \"Edition_ID\": f\"{year}{venue_id}\",\n",
    "                    \"Venue_ID\": f\"{venue_id}\",\n",
    "                    \"Conference_Edition_Name\": f\"{year} {venue}\",\n",
    "                    \"Year\": year\n",
    "            })\n",
    "            # Generate synthetic editions for the past 3 years\n",
    "            # n=random.randint(2,6)\n",
    "            for i in range(1,5):\n",
    "                edition_year = int(year) - i\n",
    "\n",
    "                Conf_editions.append({\n",
    "                    \"Edition_ID\": f\"{edition_year}{venue_id}\",\n",
    "                    \"Venue_ID\": f\"{venue_id}\",\n",
    "                    \"Conference_Edition_Name\": f\"{edition_year} {venue}\",\n",
    "                    \"Year\": edition_year\n",
    "                })                                \n",
    "                synthetic_paper_id = f\"{edition_year}{paper_id}\"\n",
    "                synthetic_doi = f\"{edition_year}{doi}\"\n",
    "                synthetic_title = f\"{edition_year} {title}\"\n",
    "                paper_edition=f\"{edition_year}{venue_id}\"\n",
    "\n",
    "                papers_data.append({\n",
    "                    \"Paper_ID\":synthetic_paper_id, \"DOI\":synthetic_doi, \"Title\":synthetic_title, \"Abstract\":abstract,\n",
    "                    \"Venue\":venue, \"publicationType\":publication_type, \n",
    "                    \"venue_id\":venue_id, \"journal_name\":journal_name, \"pages\":pages, \"volume\":volume, \n",
    "                    \"Edition_id\":paper_edition, \"Year\":edition_year, \"publicationDate\":publicationDate, \n",
    "                    \"Authors\":authors_str, \"Author_Ids\":author_ids_str, \"URL\":url, \n",
    "                    \"s2FieldsOfStudys\":s2FieldsOfStudys, \"Corresponding_Author_ID\":corresponding_author_id\n",
    "                })\n",
    "                # Add synthetic authors to author-paper relationship\n",
    "                for author_id in author_ids:\n",
    "                    author_paper_relationship.append({\"DOI\": synthetic_doi, \"Author_ID\": author_id, \"Corresponding\": author_id == corresponding_author_id})\n",
    "                for field in fields_of_study:\n",
    "                    paper_field_relationship.append({\"DOI\": synthetic_doi, \"Field_ID\": field_data[field]})\n",
    "\n",
    "        elif publication_type == \"journal\":\n",
    "            Journals_data.append({\n",
    "                \"ID\":venue_id, \n",
    "                \"Name\":(paper.get(\"publicationVenue\") or {}).get(\"name\", \"Unknown\"), \n",
    "                \"issn\":(paper.get(\"publicationVenue\") or {}).get(\"issn\", \"Unknown\"), \n",
    "                \"url\":(paper.get(\"publicationVenue\") or {}).get(\"url\", \"Unknown\")\n",
    "            })\n",
    "            paper_edition = \"N/A\"\n",
    "            for i in range(1,3):\n",
    "                journal_year=int(year) - i\n",
    "                synthetic_paper_id = f\"{journal_year}{paper_id}\"\n",
    "                synthetic_doi = f\"{journal_year}{doi}\"\n",
    "                synthetic_title = f\"{journal_year} {title}\"\n",
    "                \n",
    "                papers_data.append({\n",
    "                    \"Paper_ID\":synthetic_paper_id, \"DOI\":synthetic_doi, \"Title\":synthetic_title, \"Abstract\":abstract,\n",
    "                    \"Venue\":venue, \"publicationType\":publication_type, \n",
    "                    \"venue_id\":venue_id, \"journal_name\":journal_name, \"pages\":pages, \"volume\":volume, \n",
    "                    \"Edition_id\":paper_edition, \"Year\":journal_year, \"publicationDate\":publicationDate, \n",
    "                    \"Authors\":authors_str, \"Author_Ids\":author_ids_str, \"URL\":url, \n",
    "                    \"s2FieldsOfStudys\":s2FieldsOfStudys, \"Corresponding_Author_ID\":corresponding_author_id\n",
    "                })\n",
    "                for author_id in author_ids:\n",
    "                    author_paper_relationship.append({\"DOI\": synthetic_doi, \"Author_ID\": author_id, \"Corresponding\": author_id == corresponding_author_id})\n",
    "                for field in fields_of_study:\n",
    "                    paper_field_relationship.append({\"DOI\": synthetic_doi, \"Field_ID\": field_data[field]})\n",
    "        else:\n",
    "            paper_edition = \"unknown\"    \n",
    "        filtered_responses.append(paper)\n",
    "        writer.writerow([paper_id, doi, title, abstract, venue, publication_type, publication_type_2, venue_id, journal_name, pages, volume, paper_edition, year, publicationDate, citation_count, reference_count, authors_str, author_ids_str, url, s2FieldsOfStudys, corresponding_author_id])\n",
    "\n",
    "# Create DataFrame for author data\n",
    "author_df = pd.DataFrame(author_data).drop_duplicates()\n",
    "author_paper_df = pd.DataFrame(author_paper_relationship).drop_duplicates()\n",
    "field_df = pd.DataFrame(list(field_data.items()), columns=[\"Field_Name\", \"Field_ID\"]).drop_duplicates()\n",
    "paper_field_df = pd.DataFrame(paper_field_relationship).drop_duplicates()\n",
    "editions_df = pd.DataFrame(Conf_editions).drop_duplicates()\n",
    "conferences_df = pd.DataFrame(Conferences_data).drop_duplicates()\n",
    "journals_df = pd.DataFrame(Journals_data).drop_duplicates()\n",
    "\n",
    "papers_data_df = pd.DataFrame(papers_data).drop_duplicates()\n",
    "\n",
    "papers_data_df.to_csv(\"papers_synth.csv\", index=False)\n",
    "# Save to CSV\n",
    "journals_df.to_csv(\"journals.csv\", index=False)\n",
    "editions_df.to_csv(\"conference_editions.csv\", index=False)\n",
    "conferences_df.to_csv(\"conferences.csv\", index=False)\n",
    "author_df.to_csv(\"authors.csv\", index=False)\n",
    "author_paper_df.to_csv(\"author_paper_relationship.csv\", index=False)\n",
    "field_df.to_csv(\"fields_of_study.csv\", index=False)\n",
    "paper_field_df.to_csv(\"paper_field_relationship.csv\", index=False)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' has been created successfully.\")\n",
    "print(\"Author data has been saved to 'authors.csv'.\")\n",
    "print(\"Paper-Author relationship data has been saved to 'author_paper_relationship.csv'.\")\n",
    "print(\"Field data has been saved to 'fields_of_study.csv'.\")\n",
    "print(\"Paper-Field relationship data has been saved to 'paper_field_relationship.csv'.\")\n",
    "\n",
    "df1 = pd.read_csv(\"papers_synth.csv\")\n",
    "df2 = pd.read_csv(\"papers_og.csv\")\n",
    "\n",
    "# Merge (concatenate) them\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged CSV\n",
    "merged_df.to_csv(\"papers.csv\", index=False)\n",
    "\n",
    "print(\"CSV files merged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References CSV created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"papers.csv\")\n",
    "\n",
    "# Define the journal names (Replace with actual journal names)\n",
    "journal_1 = \"Algorithms\"\n",
    "journal_2 = \"Applied Sciences\"\n",
    "\n",
    "# Filter papers from the two journals\n",
    "journal_papers = df[(df[\"journal_name\"] == journal_1) | (df[\"journal_name\"] == journal_2)]\n",
    "\n",
    "# Select 5 random papers that are NOT from these journals\n",
    "random_papers = df[~df[\"DOI\"].isin(journal_papers[\"DOI\"])].sample(5, random_state=42)\n",
    "\n",
    "# Create a list to store references\n",
    "references = []\n",
    "\n",
    "# Assign references: Each random paper will reference all journal papers\n",
    "for _, ref_paper in random_papers.iterrows():\n",
    "    for _, journal_paper in journal_papers.iterrows():\n",
    "        references.append({\n",
    "            \"Paper_DOI\": journal_paper[\"DOI\"],\n",
    "            \"Reference_DOI\": ref_paper[\"DOI\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "references_df = pd.DataFrame(references)\n",
    "\n",
    "# Save as CSV\n",
    "references_df.to_csv(\"references_synth.csv\", index=False)\n",
    "\n",
    "print(\"References CSV created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper=sch.get_paper('10.1109/ICCNS58795.2023.10193141')\n",
    "# # paper=sch.get_paper('00000c33779acab142af6c7a6dae8b36fac0805d')\n",
    "# print(json.dumps(paper.raw_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For references, retrieve the necessary info to store the papers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'referenced_papers.csv' and other CSV files.\n",
      "Author data has been saved to 'ref_authors.csv'.\n",
      "Paper-Author relationship data has been saved to 'ref_author_paper_relationship.csv'.\n",
      "Field data has been saved to 'fields_of_study.csv'.\n",
      "Paper-Field relationship data has been saved to 'ref_paper_field_relationship.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for storing relationships and field data\n",
    "ref_author_paper_relationship = []  # List to store paper-author relationship\n",
    "ref_paper_field_relationship = []  # List to store paper-field relationship\n",
    "ref_author_data = []  # List to store author names and IDs\n",
    "\n",
    "paper_ids_arr = [paper[\"externalIds\"].get(\"DOI\") for paper in filtered_responses if paper[\"externalIds\"].get(\"DOI\")]\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(\"references_og.csv\", \"w\", newline=\"\") as ref_file, open(\"referenced_papers.csv\", \"w\", newline=\"\") as details_file:\n",
    "    ref_writer = csv.writer(ref_file)\n",
    "    details_writer = csv.writer(details_file)\n",
    "\n",
    "    # Write headers for both CSV files\n",
    "    ref_writer.writerow([\"Paper_DOI\", \"Reference_DOI\"])\n",
    "    details_writer.writerow([\n",
    "       \"Paper_ID\", \"DOI\", \"Title\", \"Abstract\", \"Venue\", \"publicationType\", \n",
    "        \"publication_type_2\", \"venue_id\", \"journal_name\", \"pages\", \"volume\", \"Edition_id\", \"Year\", \n",
    "        \"publicationDate\", \"Citations\", \"References\", \"Authors\", \"Author_Ids\", \n",
    "        \"URL\", \"s2FieldsOfStudys\", \"Corresponding_Author_ID\"\n",
    "    ])\n",
    "\n",
    "    # Iterate over each DOI from the paper list (referenced papers) / try with first 500 now\n",
    "    for doi in paper_ids_arr[:500]:\n",
    "        paper = sch.get_paper(doi)  # Fetch paper details\n",
    "        ref_count = getattr(paper, \"referenceCount\", \"Unknown\")\n",
    "\n",
    "        if paper and hasattr(paper, \"references\"):  # Ensure valid response\n",
    "            if ref_count < 1:\n",
    "                n = 0  # No references available\n",
    "            elif ref_count < 5:\n",
    "                n = random.randint(1, ref_count)\n",
    "            elif 5 < ref_count < 10:\n",
    "                n = random.randint(5, 6)\n",
    "            else:  # ref_count >= 10\n",
    "                n = random.randint(7, 10)\n",
    "\n",
    "            top_references = paper.references[:n]  # Get top n references\n",
    "\n",
    "            for reference in top_references:\n",
    "                ref_doi = reference.externalIds[\"DOI\"] if reference.externalIds and \"DOI\" in reference.externalIds else \"Unknown\"\n",
    "                if ref_doi == \"Unknown\":\n",
    "                    continue  # Skip if DOI is unknown\n",
    "\n",
    "                # Extract reference details\n",
    "                ref_paper_id = getattr(reference, \"paperId\", \"Unknown\")\n",
    "                ref_title = getattr(reference, \"title\", \"Unknown\")\n",
    "                ref_abstract = getattr(reference, \"abstract\", \"\")\n",
    "                ref_venue = getattr(reference, \"venue\", \"Unknown\")\n",
    "                ref_publication_type = getattr(getattr(reference, \"publicationVenue\", {}), \"type\", \"Unknown\")\n",
    "                ref_venue_id = getattr(getattr(reference, \"publicationVenue\", {}), \"id\", \"Unknown\")\n",
    "\n",
    "                ref_publication_type_2 = getattr(reference, \"publicationTypes\", [])\n",
    "                ref_journal_name = getattr(getattr(reference, \"journal\", {}), \"name\", \"Unknown\")\n",
    "                ref_pages = getattr(getattr(reference, \"journal\", {}), \"pages\", \"Unknown\")\n",
    "                ref_volume = getattr(getattr(reference, \"journal\", {}), \"volume\", \"Unknown\")\n",
    "                ref_year = getattr(reference, \"year\", \"Unknown\")\n",
    "                ref_publication_date = getattr(reference, \"publicationDate\", \"Unknown\")\n",
    "                ref_citation_count = getattr(reference, \"citationCount\", \"Unknown\")\n",
    "                ref_reference_count = getattr(reference, \"referenceCount\", \"Unknown\")\n",
    "                ref_s2_fields_of_study = ', '.join(sorted({s2fs.get('category', \"Unknown\") for s2fs in getattr(reference, \"s2FieldsOfStudy\", [])}))\n",
    "                \n",
    "                # Format authors\n",
    "                ref_authors = [str(getattr(author, 'name', 'Unknown')) for author in getattr(reference, \"authors\", [])]\n",
    "                ref_authors_ids = [str(getattr(author, 'authorId', 'Unknown')) for author in getattr(reference, \"authors\", [])]\n",
    "\n",
    "                ref_url = getattr(reference, \"url\", \"Unknown\")\n",
    "                \n",
    "                # Ensure authors and author IDs match in length\n",
    "                if len(ref_authors) != len(ref_authors_ids):\n",
    "                    continue\n",
    "\n",
    "                ref_corresponding_author_id = ref_authors_ids[0] if ref_authors_ids else \"Unknown\"\n",
    "\n",
    "                # Handle authors and relationships\n",
    "                for author_name, author_id in zip(ref_authors, ref_authors_ids):\n",
    "                    ref_author_data.append({\"Author_Name\": author_name, \"Author_ID\": author_id})\n",
    "                    ref_author_paper_relationship.append({\"DOI\": ref_doi, \"Author_ID\": author_id, \"Corresponding\": (author_id == ref_corresponding_author_id)})\n",
    "\n",
    "                # Handle fields of study\n",
    "                fields_of_study = {s2fs.get('category', \"Unknown\") for s2fs in getattr(reference, \"s2FieldsOfStudy\", [])}\n",
    "\n",
    "                # Assign unique IDs to fields of study\n",
    "                for field in fields_of_study:\n",
    "                    if field not in field_data:\n",
    "                        field_data[field] = field_id_counter\n",
    "                        field_id_counter += 1\n",
    "\n",
    "                # Create paper-field relationship\n",
    "                for field in fields_of_study:\n",
    "                    ref_paper_field_relationship.append({\"DOI\": ref_doi, \"Field_ID\": field_data[field]})\n",
    "\n",
    "\n",
    "                if ref_publication_type == \"journal\":\n",
    "                    Journals_data.append({\n",
    "                        \"ID\":venue_id, \n",
    "                        \"Name\":getattr(getattr(reference, \"publicationVenue\", {}), \"name\", \"Unknown\"),\n",
    "                        \"issn\":getattr(getattr(reference, \"publicationVenue\", {}), \"issn\", \"Unknown\"),\n",
    "                        \"url\":getattr(getattr(reference, \"publicationVenue\", {}), \"url\", \"Unknown\")\n",
    "                        })\n",
    "                    paper_edition = \"N/A\"\n",
    "                elif ref_publication_type == \"conference\":\n",
    "                    Conferences_data.append({\n",
    "                        \"ID\":venue_id, \n",
    "                        \"Name\":getattr(getattr(reference, \"publicationVenue\", {}), \"name\", \"Unknown\"),\n",
    "                        \"url\":getattr(getattr(reference, \"publicationVenue\", {}), \"url\", \"Unknown\")\n",
    "                        })\n",
    "                    paper_edition=f\"{ref_year}{ref_venue_id}\"\n",
    "                    Conf_editions.append({\n",
    "                            \"Edition_ID\": paper_edition,\n",
    "                            \"Venue_ID\": ref_venue_id,\n",
    "                            \"Conference_Edition_Name\": f\"{ref_year} {venue}\",\n",
    "                            \"Year\": ref_year\n",
    "                    })\n",
    "                else:\n",
    "                    paper_edition = \"Unknown\"\n",
    "\n",
    "                ref_writer.writerow([doi, ref_doi])\n",
    "\n",
    "                # Write the reference data to CSV\n",
    "                details_writer.writerow([\n",
    "                    ref_paper_id, ref_doi, ref_title, ref_abstract, ref_venue, ref_publication_type, \n",
    "                    ref_publication_type_2, ref_venue_id, ref_journal_name, ref_pages, ref_volume, paper_edition, ref_year, \n",
    "                    ref_publication_date, ref_citation_count, ref_reference_count, \n",
    "                    \", \".join(ref_authors), \", \".join(ref_authors_ids), ref_url, ref_s2_fields_of_study, \n",
    "                     ref_corresponding_author_id \n",
    "                ])\n",
    "\n",
    "# Create DataFrames for authors, paper-author, fields, and paper-field relationships\n",
    "author_df = pd.DataFrame(ref_author_data).drop_duplicates()\n",
    "author_paper_df = pd.DataFrame(ref_author_paper_relationship).drop_duplicates()\n",
    "field_df = pd.DataFrame(list(field_data.items()), columns=[\"Field_Name\", \"Field_ID\"]).drop_duplicates()\n",
    "paper_field_df = pd.DataFrame(ref_paper_field_relationship).drop_duplicates()\n",
    "editions_df = pd.DataFrame(Conf_editions).drop_duplicates()\n",
    "conferences_df = pd.DataFrame(Conferences_data).drop_duplicates()\n",
    "journals_df = pd.DataFrame(Journals_data).drop_duplicates()\n",
    "# Save to CSV\n",
    "journals_df.to_csv(\"journals.csv\", index=False)\n",
    "editions_df.to_csv(\"conference_editions.csv\", index=False)\n",
    "conferences_df.to_csv(\"conferences.csv\", index=False)\n",
    "# Save the DataFrames to CSV files\n",
    "author_df.to_csv(\"ref_authors.csv\", index=False)\n",
    "author_paper_df.to_csv(\"ref_author_paper_relationship.csv\", index=False)\n",
    "field_df.to_csv(\"fields_of_study.csv\", index=False)\n",
    "paper_field_df.to_csv(\"ref_paper_field_relationship.csv\", index=False)\n",
    "\n",
    "print(\"Data has been written to 'referenced_papers.csv' and other CSV files.\")\n",
    "print(\"Author data has been saved to 'ref_authors.csv'.\")\n",
    "print(\"Paper-Author relationship data has been saved to 'ref_author_paper_relationship.csv'.\")\n",
    "print(\"Field data has been saved to 'fields_of_study.csv'.\")\n",
    "print(\"Paper-Field relationship data has been saved to 'ref_paper_field_relationship.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"references_og.csv\")\n",
    "df2 = pd.read_csv(\"references_synth.csv\")\n",
    "\n",
    "# Merge (concatenate) them\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged CSV\n",
    "merged_df.to_csv(\"references.csv\", index=False)\n",
    "\n",
    "print(\"CSV files merged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
